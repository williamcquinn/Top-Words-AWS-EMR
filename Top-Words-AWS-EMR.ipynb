{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count on Amazon EMR\n",
    "\n",
    "---\n",
    "\n",
    "#### Tasks: \n",
    "\n",
    "- Finding top 100 words and their counts based on word count for the BookReviews_5M dataset\n",
    "- Calculate average and standard deviation of execution times over 3 runs for these three settings:\n",
    "    1. BookReviews_1M - 1 master + 1 worker node \n",
    "    2. BoookReviews_5M - 1 master + 1 worker node\n",
    "    3. BookReviews_5M - 1 master + 3 worker nodes\n",
    "\n",
    "---\n",
    "\n",
    "#### Documentation:\n",
    "\n",
    "PySpark API Documentation: https://spark.apache.org/docs/latest/api/python/index.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e9ffad125645a0a81dae1c3a746fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1615356276276_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-18-86.us-west-2.compute.internal:20888/proxy/application_1615356276276_0005/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-23-177.us-west-2.compute.internal:8042/node/containerlogs/container_1615356276276_0005_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1-amzn-0 3.0.1+amzn.0"
     ]
    }
   ],
   "source": [
    "# Initialize Spark\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "print (spark.version, pyspark.version.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79942231a4454df19e65c3446f1de7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Record the starting time of execution for timing this notebook\n",
    "\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2099db41fd408f88531fc22d461a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HDFS file path of the 5M dataset.\n",
    "dataFileName = \"hdfs:///data/BookReviews_5M.txt\"\n",
    "\n",
    "\n",
    "# Read data from the above file path and convert it to a dataframe. \n",
    "textDF = spark.read.text(dataFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examining the data\n",
    "\n",
    "Task: \n",
    "1. Examine the contents of the dataframe.\n",
    "\n",
    "Expected output: \n",
    "1. Print the schema of the raw dataframe, as well as its first 25 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3956aed928934ea6b2b1c80f3ce1b273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|This was the firs...|\n",
      "|Also after going ...|\n",
      "|As with all of Ms...|\n",
      "|I've not read any...|\n",
      "|This romance nove...|\n",
      "|Carolina Garcia A...|\n",
      "|Not only can she ...|\n",
      "|Once again Garcia...|\n",
      "|The timing is jus...|\n",
      "|Engaging. Dark. R...|\n",
      "|Set amid the back...|\n",
      "|This novel is a d...|\n",
      "|If readers are ad...|\n",
      "| Reviewed by Phyllis|\n",
      "|      APOOO BookClub|\n",
      "|A guilty pleasure...|\n",
      "|In the tradition ...|\n",
      "|Beryl Unger, top ...|\n",
      "|What follows is a...|\n",
      "|The book flap say...|\n",
      "|I'd never before ...|\n",
      "|The novel's narra...|\n",
      "|It is centered on...|\n",
      "|If you like moder...|\n",
      "|Beryl Unger is a ...|\n",
      "+--------------------+\n",
      "only showing top 25 rows"
     ]
    }
   ],
   "source": [
    "textDF.printSchema()\n",
    "textDF.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning the data\n",
    "\n",
    "Task:\n",
    "1. Remove all punctuations and convert all characters to lower case.\n",
    "\n",
    "Expected output:\n",
    "1. The first 25 rows of a dataframe, with a column containing the cleaned sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7959cb113e904419bfcdc1b8ec2d52b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, col, lower\n",
    "def removePunctuation(column):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\"\"\"\n",
    "    return trim(lower(regexp_replace(column, \"[^A-Za-z0-9 ]\", \"\"))).alias(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f528c0fcec4193a83e121a15b50cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<b'trim(lower(regexp_replace(value, [^A-Za-z0-9 ], ))) AS `sentence`'>"
     ]
    }
   ],
   "source": [
    "print(removePunctuation(textDF.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21d78fe4e19479fa090ada98afb36bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            sentence|\n",
      "+--------------------+\n",
      "|this was the firs...|\n",
      "|also after going ...|\n",
      "|as with all of ms...|\n",
      "|ive not read any ...|\n",
      "|this romance nove...|\n",
      "|carolina garcia a...|\n",
      "|not only can she ...|\n",
      "|once again garcia...|\n",
      "|the timing is jus...|\n",
      "|engaging dark rea...|\n",
      "|set amid the back...|\n",
      "|this novel is a d...|\n",
      "|if readers are ad...|\n",
      "| reviewed by phyllis|\n",
      "|      apooo bookclub|\n",
      "|a guilty pleasure...|\n",
      "|in the tradition ...|\n",
      "|beryl unger top e...|\n",
      "|what follows is a...|\n",
      "|the book flap say...|\n",
      "|id never before r...|\n",
      "|the novels narrat...|\n",
      "|it is centered on...|\n",
      "|if you like moder...|\n",
      "|beryl unger is a ...|\n",
      "+--------------------+\n",
      "only showing top 25 rows"
     ]
    }
   ],
   "source": [
    "# Execute the column expressions generated by removePunctuation() to clean the sentences\n",
    "removedDF = textDF.select(removePunctuation(textDF.value))\n",
    "removedDF.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get dataframe containing unique words and their counts\n",
    "\n",
    "Task:\n",
    "1. Split each sentence into words based on the delimiter space (' ').\n",
    "2. Put each word in each sentence row into their own rows. Put results into a new dataframe.\n",
    "3. Print out the first 5 rows of the dataframe.\n",
    "\n",
    "Expected output: \n",
    "1. First 5 rows of the output dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d5e761ebc841c482a4ae11e114a1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| word|\n",
      "+-----+\n",
      "| this|\n",
      "|  was|\n",
      "|  the|\n",
      "|first|\n",
      "| time|\n",
      "+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# We assemble the 'split' and 'explode' column expressions, then apply them to the sentence column\n",
    "\n",
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "wordsDF = removedDF.select(explode(split(removedDF.sentence, ' ')).alias('word'))\n",
    "wordsDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695466fbac5a468581d732c1ad69e20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          word|\n",
      "+--------------+\n",
      "|          this|\n",
      "|           was|\n",
      "|           the|\n",
      "|         first|\n",
      "|          time|\n",
      "|             i|\n",
      "|          read|\n",
      "|garciaaguilera|\n",
      "|             i|\n",
      "|          came|\n",
      "|          upon|\n",
      "|           the|\n",
      "|          name|\n",
      "|            of|\n",
      "|          this|\n",
      "|          book|\n",
      "|            on|\n",
      "|          live|\n",
      "|          with|\n",
      "|         regis|\n",
      "|           and|\n",
      "|         kelly|\n",
      "|          this|\n",
      "|          book|\n",
      "|           was|\n",
      "+--------------+\n",
      "only showing top 25 rows"
     ]
    }
   ],
   "source": [
    "# Filter out all empty rows in the dataframe. \n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "oneword = wordsDF.filter(\"word != ''\")\n",
    "oneword.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8afdd224a1439c947623241a0379c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                word|count|\n",
      "+--------------------+-----+\n",
      "|              online|40394|\n",
      "|              brands|19389|\n",
      "|                hope|33903|\n",
      "|                150x|  129|\n",
      "|            everyday|12140|\n",
      "|               input|33909|\n",
      "|               spoil|  260|\n",
      "|              spared|  162|\n",
      "|               poppy|   39|\n",
      "|               exept|   89|\n",
      "|hrefonkyohtrc2707...|    2|\n",
      "|            priority| 2840|\n",
      "|           squealing|  138|\n",
      "|            foamlike|   23|\n",
      "|              outfit|  543|\n",
      "|              filing|  538|\n",
      "|           digitized|  277|\n",
      "|           viewpoint|  129|\n",
      "|              peolpe|   15|\n",
      "|            wristlet|   28|\n",
      "|             flashed|  806|\n",
      "|        releasedhave|    1|\n",
      "|hrefharmony880uni...|    1|\n",
      "|     advertisedgreat|   14|\n",
      "|            recibido|   41|\n",
      "+--------------------+-----+\n",
      "only showing top 25 rows"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by unique words, count each group\n",
    "wordcount = oneword.groupby('word').count()\n",
    "wordcount.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sorting the word count dataframe in descending.\n",
    "\n",
    "Task: \n",
    "1. Sort the previous dataframe by the counts column in a descending manner. Put results into a new dataframe. \n",
    "\n",
    "Expected output:\n",
    "1. First 25 rows of the sorted word count dataframe. The first row would have the maximum count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dc3abcd8e8445bb74b57a94a7a6585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| word|   count|\n",
      "+-----+--------+\n",
      "|  the|10642903|\n",
      "|    i| 6326216|\n",
      "|   to| 5607568|\n",
      "|  and| 5537690|\n",
      "|    a| 5166838|\n",
      "|   it| 4654902|\n",
      "|   is| 3242588|\n",
      "|  for| 2860227|\n",
      "| this| 2845219|\n",
      "|   of| 2782166|\n",
      "|   my| 2319813|\n",
      "|   in| 2147373|\n",
      "| with| 2046990|\n",
      "| that| 1983044|\n",
      "|   on| 1758801|\n",
      "|  you| 1754054|\n",
      "| have| 1632887|\n",
      "|  but| 1508591|\n",
      "|  not| 1460730|\n",
      "|  was| 1434985|\n",
      "|   as| 1185866|\n",
      "|  are| 1007811|\n",
      "|   so|  994529|\n",
      "|great|  988223|\n",
      "| very|  893737|\n",
      "+-----+--------+\n",
      "only showing top 25 rows"
     ]
    }
   ],
   "source": [
    "# Sort the dataframe by the 'count' column\n",
    "wordCountsSortedDF = wordcount.sort(col(\"count\").desc())\n",
    "wordCountsSortedDF.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Record the execution time\n",
    "\n",
    "Your task: \n",
    "1. Print the execution time.\n",
    "\n",
    "Expected output: The execution time. No particular value is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269052aa04304b4789898b978dd5a3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.44440722465515"
     ]
    }
   ],
   "source": [
    "# Print the time since execution start.\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Saving the sorted word counts directly to S3 as a CSV file\n",
    "\n",
    "NOTE: Spark uses a distributed memory system, and stores working data in fragments known as \"partitions\". This is advantageous when a Spark cluster spans multiple machines, as each machine will only require part of the working data to do its own job. By default, Spark will save each of these data partitions into a individual file to avoid I/O collisions. We want only one output file, so we'll need to fuse all the data into a single partition first. \n",
    "\n",
    "Task: \n",
    "1. Coalesce the previous dataframe to one partition. This makes sure that all our results will end up in the same CSV file. \n",
    "2. Save the 1-partition dataframe to S3 using the DataFrame.write.csv() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64cf2067bf24d368918bf90456b83b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save results to S3\n",
    "\n",
    "#wordCountsSortedDF.coalesce(1).write.csv(\"s3://willquinnbucket/W9/wordcountAWS.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3de04df7d1a483b80e5676c5704584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stop Spark session\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Execution times on different dataset and settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset | #Master Nodes | #Core Nodes | Runtime_1 | Runtime_2 | Runtime_3 | Mean | Std |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 1M | 1 | 1 | 42.86703324317932 | 43.33017683029175 | 40.96249055862427 | 42.387 | 1.025 | \n",
    "| 5M | 1 | 1 | 105.99708557128906 | 106.47394895553589 | 105.98241972923279 | 106.151 | 0.228 | \n",
    "| 5M | 1 | 3 | 49.603049516677856 | 50.460874795913696 | 49.93751811981201 | 50.000 | 0.353 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc86db8b574486485f511ddaadae643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "42.38656687736511\n",
      "106.15115141868591\n",
      "50.000480810801186\n",
      "Standard Deviation\n",
      "1.0245716232552018\n",
      "0.2283308404897207\n",
      "0.3530243407721914"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Mean')\n",
    "print(np.mean([42.86703324317932, 43.33017683029175, 40.96249055862427]))\n",
    "print(np.mean([105.99708557128906, 106.47394895553589, 105.98241972923279]))\n",
    "print(np.mean([49.603049516677856, 50.460874795913696, 49.93751811981201]))\n",
    "print('Standard Deviation')\n",
    "print(np.std([42.86703324317932, 43.33017683029175, 40.96249055862427]))\n",
    "print(np.std([105.99708557128906, 106.47394895553589, 105.98241972923279]))\n",
    "print(np.std([49.603049516677856, 50.460874795913696, 49.93751811981201]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
